\documentclass[architecture]{compas2018}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\toappear{1} % Conserver cette ligne pour la version finale

\usepackage{tikz}
\tikzset{
  hwblock/.style={draw, rectangle, rounded corners=.3, very thick, fill=black!5, font=\sf, minimum height=5ex},
  hwbus/.style={very thick,>=stealth},
  hwwire/.style={thin, >=stealth, },
  hwword/.style={draw, rectangle, minimum height=3ex},
  bitwidth/.style={font=\scriptsize,midway,right}
}

\newcommand{\reg}{\textit{reg}}
\newcommand{\const}{\textit{const}}
\newcommand{\shiftval}{\textit{shiftval}}
\newcommand{\cond}{\textit{cond}}
\newcommand{\ctr}{\textit{ctr}}
\newcommand{\size}{\textit{size}}
\newcommand{\addr}{\textit{addr}}

\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}
\begin{document}

\title{Une architecture minimisant les échanges\\ entre processeur et mémoire}

\author{Florent de Dinechin, \\Sébastien Michelland, Maxime Darrin, Antonin Dudermel, Alban Reynaud}

\address{
  % \begin{tabular}{cc}
  %   ENS-Lyon & INSA Lyon \\
  %   \texttt{nom.prenom@ens-lyon.org} \\
  % \end{tabular}
}

\date{\today}

\maketitle

\begin{abstract}
Dans une architecture de von Neumann, le processeur communique avec la mémoire au moyen d'un bus d'adresses et d'un bus de données de grandes tailles (entre 16 et 64 bits).
C'est une contrainte pour l'encodage des instructions du processeur, comme le montre un survol historique des jeux d'instruction dominants.
Or les échanges de données représentent le gros de l'énergie dépensée.
Cet article fait l'exercice de lever cette contrainte, dans le but de minimiser le nombre de bits échangés entre le processeur et la mémoire.
Il décrit une architecture 64 bits dont la mémoire est adressable par bit, avec un seul signal de données entre le processeur et la mémoire.
Ceci permet d'avoir des instructions de taille arbitraire.
Pour ne pas devoir envoyer une adresse complète à la mémoire à chaque accès, la solution proposée est l'usage de pointeurs auto-incrémentés dupliqués dans la mémoire et le processeur.

Cet article décrit aussi une expérience pédagogique réalisée à l'ENS-Lyon (ce qui explique en partie certains choix simplistes).
Un premier jeu d'instruction a été défini en TD et son encodage choisi à la main.
Ceci a permis aux étudiants d'écrire en binôme un assembleur et un simulateur, puis plusieurs milliers de lignes de programmes allant du petit noyau de calcul au jeu vidéo et à l'émulateur.
Sur les traces de ces programmes, on a pu ensuite calculer un encodage optimal des instructions des instructions en fonction de leur fréquence via des arbres de Huffmann, et les comparer à l'encodage initial.
On arrive à une taille moyenne d'instruction entre 9 et 15 bits suivants les programmes.
 Ces expérimentations montrent aussi que le code représente une part importante des données transitant entre processeur et mémoire. 
 L'article discute enfin les limites de cette approche, et d'éventuelles solutions pour y remédier.
\end{abstract}

%=========================================================
\section{Introduction et motivation}
% =========================================================
Cet article s'intéresse à l'encodage du jeu d'instruction d'un processeur de von Neumann, interfacé à une mémoire par un bus d'adresse et un bus de données comme schématisé sur la figure~\ref{fig:mvn}.

\newcommand{\figVonNeumann}{
  \begin{tikzpicture}
    \node[hwblock, minimum width=15ex,minimum height=15ex] (p) at (0,0)  {Processeur} ;
    \node[hwblock, minimum width=15ex,minimum height=15ex] (m) at (30ex,0)  {Mémoire} ;
    \draw[hwbus,->] (p.25) -- (m.155) node[midway,above=1ex]{adresse} node[midway]{/} node[midway, below right]{$w_a$};
    \draw[hwbus,<->] (p.335) -- (m.205) node[midway,below]{données} node[midway]{/} node[midway, above left]{$w_d$};
  \end{tikzpicture}
}

\begin{figure}[ht]
  \begin{center}
    \figVonNeumann
  \end{center}
  \caption{Une machine de von Neumann.}
  \label{fig:mvn} \index{von Neumann}\index{machine de von Neumann}
\end{figure}

\subsection{Généralités}
Le jeu d'instruction d'un processeur (Instruction Set Architecture ou ISA) reflète l'état de la loi de Moore à l'époque de sa conception.
Celle-ci se traduit par exemple par un doublement de la quantité de mémoire intégrée sur une puce tous les deux ans.
Comme il faut bien adresser cette mémoire, le bus mémoire suit, et sa taille ($w_a$ sur la figure) grandit donc d'un bit tous les deux ans.
Ceci se traduit à son tour par une croissance de la taille des registres qui, dans un processeur, peuvent adresser la mémoire.
Toutefois, ici, le fétichisme des architectes pour les puissances de 2 intervient, et on a observé une croissance de ces registres par palier: de 8 bits aux temps héroïques à 16 bits dans les années 70, 32 bits dans les années 80, et 64 bits dans les années 2000.
Les adresses sur 64 bits devraient ainsi suffire pour plusieurs dizaines d'années, mais l'on se gardera bien de faire des pronostics si lointains.

\iffalse % c'est fort intéressant mais on s'en fout
La croissance du bus de données a suivi avec du retard, pour plusieurs raisons.
La première est que la loi de Moore doit aussi fournir assez de transistors au processeur pour calculer sur des données de plus en plus grandes.
Mais la complexité des principales opérations d'un processeur travaillant sur $n$ bits est en $n$, en $n\log n$ ou au pire en $n^2$: si l'on a pu être à l'étroit jusque dans les années 90 pour construire un processeur qui peut calculer sur des adresses mémoires, ce n'est plus le cas depuis.
La seconde raison est que les ordinateurs servent beaucoup à travailler sur du texte, donc des octets.
On a donc vu des processeurs très populaires 8/16 bits, c'est à dire $w_d=8$ et  $w_a = 16$: les z80, 6502, 8088; des processeurs 16/32 bits (68000, 80286 à 486); et même une variante 8/32 bits, le 68008. Puis l'industrie a convergé vers 32/32 avec l'arrivée des processeurs RISC  (SPARC,  ARM et Power)  puis et 64/64 avec AMD64 et ARM64.
Ainsi,  
De nos jours, les processeurs ont des registres de plusieurs centaines de bits (AMD64 SSE* puis AVX*, ARM Neon), encore une fois parce que la loi de Moore le permet.
Mais ces registres sont des vecteurs de données d'au plus 64 bits.
\fi



Une question intéressante, et qui commence à toucher le jeu d'instruction, est l'adressabilité, c'est-à-dire la granularité à laquelle on peut adresser la mémoire.
L'ancêtre 4004 adressait sa mémoire par cases de 4 bits, ce qui correspondait au besoin du décimal codé en binaire. Le processeur Saturn des calculettes HP était aussi un processeur 4/20 bits.
La plupart des processeurs adressent leur mémoire par octet pour être efficace sur le traitement de texte.

Cela dit, dans un processeur 32 bits, les données de 32 bits doivent avoir des adresses dites alignées, c'est à dire multiples de 4 octets. Un accès non aligné se traduit selon les ISA par une faute ou par un accès beaucoup plus lent.


\subsection{Pourquoi pas l'adressabilité au bit près?}
Ceci nous amène à la première constatation. Dès lors que les adresses font 64 bits, on peut parfaitement décider  que le adresses seront des adresses de bits.
On perd un facteur 8 en quantité de mémoire adressable.
Ce qui aurait été inacceptable à l'époque des adresses sur 16 bits est indolore pour quelques années avec un espace d'adressage sur 64 bits: il reste tout de même $2^{61}\approx 2.10^{18}$ bits, ou 2 exabits, à adresser.


Attention, on parle de l'abstraction offerte par le jeu d'instruction, pas de l'interface physique.
Les deux sont déjà différentes dans les processeurs actuels.
Dans le jeu d'instruction AMD64, l'ISA définit une mémoire adressable par octet, avec des contraintes d'alignements pour les accès à des données plus grandes.
Par contre l'accès physique à la mémoire se fait à travers un cache qui, côté processeur, offre l'adressage par octet, mais côté mémoire physique  réalise des accès alignés sur une grande puissance de 2 correspondant à la taille de la ligne de cache.

Passer d'un adressage par octet à un adressage au bit complexifie légèrement l'interface processeur-cache.
On peut estimer que cela ajoute trois niveaux de multiplexeurs au décodage de la ligne de cache, un changement plus quantitatif que qualitatif.
Cela dit, dans tout cet article nous ignorons sereinement cette problématique.
Nous ne remettrons les pieds sur terre que dans la discussion de conclusion.


Mais que gagne-t-on à avoir une adresse pour chaque bit?  On peut manipuler des données au bit près.
Surtout, on peut manipuler des données de taille variables au bit près.
Comme domaine d'application, on peut citer les UNUM, un format de représentation des nombres flottants de taille variable et auto-descriptif (les tailles d'exposant et de mantisse sont encodées dans un en-tête) proposé par  Gustafson en 2015 \cite{2015-02-GUSTAFSON}.
Cette proposition est déjà abandonnée par son auteur \cite{2016-09-TICHY} malgré quelques bonnes idées, mais une de ses principales motivations reste: les transferts de données sont extrêmement coûteux.
D'après Dally, en technologie 28nm, le calcul d'une multiplication-addition flottante sur des données 64 bits coûte 50pJ, et l'accès aux registres sur puce est du même ordre de grandeur, alors qu'une lecture de 64 bits de la DRAM coûte 4000pJ.
\todo{F2D: citation}

Il y a aussi des applications, comme les réseaux de neurones, qui se contentent très bien de données sur de très petites précision, voire des données binaires \cite{AndriCRB16,AlemdarEtAl2017:TernaryCNN,AmiriEtAl2018:mixedPrecCNN,Preusser:DATE2018:heteroCNN}. 

\subsection{Pourquoi pas un jeu d'instruction au bit près?}

\todo{F2D}

\subsection{Contexte de ce travail}
Résumé des objectifs pédagogiques du cours ASR1

\todo{F2D}
\subsection{Plan}

\todo{F2D}


\section{Présentation du jeu d'instruction initial}
Le jeu d'instruction décrit dans cette section est l'aboutissement de deux séances de TD dans lesquelles on a essayé de discuter les tenants et les aboutissants de chaque décision.
Les choix faits ne sont pas toujours ceux qui étaient considérés les meilleurs: nous avons aussi privilégié la faisabilité dans le temps limité consacré au module d'ASR1.

\subsection{Architecture générale et interface mémoire}

\begin{figure}[h]
  \caption{Overview of the processor-memory interface}
  \label{fig:overview}
    \begin{center}
  \begin{tikzpicture}
    \node[hwblock, minimum width=25ex,minimum height=25ex] (p) at (-10ex,0)  {Processor} ;
    \node[hwblock, minimum width=25ex,minimum height=25ex, align=center] (m) at (30ex,0)  {Serial\\ Memory} ;
    
    \draw (p.north west)  ++(4ex,-3ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{PC} ;
    \draw (p.north west)  ++(4ex,-7ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{SP} ;
    \draw (p.north west)  ++(4ex,-11ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A0} ;
    \draw (p.north west)  ++(4ex,-15ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A1} ;
    
    \draw (m.north east)  ++(-4ex,-3ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{PC} ;
    \draw (m.north east)  ++(-4ex,-7ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{SP} ;
    \draw (m.north east)  ++(-4ex,-11ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A0} ;
    \draw (m.north east)  ++(-4ex,-15ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A1} ;

    \draw[hwwire,->] (p.40) -- (m.140) node[midway,above]{\texttt{Dpm}};
    \draw[hwwire,<-] (p.35) -- (m.145) node[midway,below]{\texttt{Dmp}};

    \draw[hwwire,->] (p.10) -- (m.170) node[midway,above]{\texttt{Read}};
    \draw[hwwire,->] (p.355) -- (m.185) node[midway,above]{\texttt{Write}};
    \draw[hwwire,->] (p.340) -- (m.200) node[midway,above]{\texttt{SetCounter}};
    \draw[hwwire,->] (p.322) -- (m.218) node[midway,above]{\texttt{Select}};
    \draw[hwwire,->] (p.320) -- (m.220) node[midway,above]{};
    \draw[hwwire,<-] (m.south) -- ++(0,-4ex) -- ++(-50ex,0) node[left]{Ck};
    \draw[hwwire,<-] (p.south) -- ++(0,-4ex);
    \draw[hwwire,-] (p.south)  ++(-1ex, 0) -- ++(1ex,1ex) -- ++(1ex,-1ex); % horloge
    \draw[hwwire,-] (m.south)  ++(-1ex, 0) -- ++(1ex,1ex) -- ++(1ex,-1ex); % horloge
  \end{tikzpicture}
  \end{center}
\end{figure}

\subsection{Registres généralistes}
Dans cette expérience nous avons fixé le nombre de registres à 8.
C'est un choix arbitraire et discutable, motivé par des raisons pédagogiques (rencontrer cette limite dès l'écriture de programmes simples) et par une raison pratique (encoder le numéro de registre sur aussi peu de bits que possible).

Les registres généralistes sont notés r0 à r7.
Ils sont tous parfaitement identiques, sauf r7 qui reçoit l'adresse de retour en cas de \texttt{call}.

\paragraph*{Autocritique} Les architectures modernes offrent typiquement entre 16 et 64 registres.
Elles offrent également des mécanismes qui exposent dans le jeu d'instruction un sous-ensemble des registres architecturaux, soit de manière explicite (les fenêtres de registres du SPARC), soit de manière implicite (le techniques de renommage qui permettent l'exécution superscalaire).

On pourrait aussi avoir un nombre de registres beaucoup plus grand avec un encodage compact des registres les plus utilisés.

\subsection{Format général des mnémoniques}
Les instructions commencent toutes par un mnémonique, suivi des opérandes, le tout séparé par des espaces.

Les instructions ALU viennent en version 2 et 3 opérandes, la destination venant toujours en premier.
Par exemple, \\
 \begin{tabular}{lcl}
 \texttt{add2 r0 r1}&& réalise $r_0 \leftarrow r_0+r_1$. \\
 \texttt{add3 r0 r1 r2}&& réalise $r_0 \leftarrow r_1+r_2$.
 \end{tabular}
 
Le suffixe \texttt{i} signifie que le dernier opérande est une constante immédiate, par exemple:\\
 \begin{tabular}{lcl}
 \texttt{add2 r0 1}&& réalise $r_0 \leftarrow r_0+1$. \\
 \end{tabular}

L'assemblage commence à l'adresse 0, qui est celle à laquelle notre processeur démarre.

 
Sucre syntaxique offert par l'assembleur:
\begin{itemize}
\item On peut utiliser des labels pour les sauts.
\item Le mot-clé \texttt{.const n xxxx}  réserve $n$ bits de mémoire, initialisés à la constante xxxx, qui est priée de tenir sur $n$ bits.
\item Les constante hexadécimales sont préfixées par \texttt{0x}, par exemple \texttt{0xff}
\item Le commentaire est introduit par un point-virgule \texttt{;}
\end{itemize}
 

Exemple de programme :
\begin{verbatim}
  let r0 17     ; l'assembleur va calculer combien de bits il faut pour 17
boucle:	
  sub2i r0 1    ; encodé en 9 bits, et ceci est un commentaire
  jumpif nz boucle  ; encodé en 16 bits, signifie  jump -25 
\end{verbatim}

\subsection{Le jeu d'instructions et son encodage intial}



La table \ref{tab:opcodes} décrit l'opcode qui commence chaque instruction.

Remarques en vrac: 
\begin{itemize}
\item le not logique est implémenté par xor -1
\item la direction du shift est encodée dans un bit après l'instruction pour économiser un opcode. On aurait pu définir deux opcodes comme pour \texttt{readze}/\texttt{readse} mais c'est plus rigolo de lire \texttt{shift left r1 1}.
\end{itemize}


\begin{table}[!h]
  \caption{Liste des instructions.}
  \label{tab:opcodes}
  Le codage de Huffmann des instructions est basée sur les statistiques des années précédentes.
  Les opérandes d'une instruction la suivent en mémoire. Ils sont encodés comme suit:
  \begin{itemize}
\item \textit{reg} $\in \{\mathtt{r0}, \mathtt{r1}, ..., \mathtt{r7}\}$ et est encodé par le numéro du registre en binaire.
\item \textit{const}, \textit{shiftval} et \textit{addr} sont définis par la table \ref{tab:constantes}. La dernière colonne de la table  \ref{tab:opcodes} précise si une constante est étendue avec son signe (s) ou des zéros (z).   
\item  \textit{cond} est défini par la table~\ref{tab:conditions}.
\item \ctr\ est défini par la table~\ref{tab:counters}.
\item \textit{dir} peut être le mnemnonique \texttt{left}, encodé par 0, ou le mnemonique \texttt{right}, encodé par 1.
\end{itemize}
\begin{center}
  \begin{tabular}{|l|l|l|l|l|c|}
    \hline  
    opcode  & mnemonic        & operands                      & description                                          & ext. & {MàJ flags} \\
    \hline  
    \hline  
    0000    & \texttt{add2}   & \reg\ \reg\                   & addition                                             &      & zcvn        \\
    \hline
    0001    & \texttt{add2i}  & \reg\ \const\                 & add immediate constant                               & z    & zcvn        \\
    \hline
    0010    & \texttt{sub2}   & \reg\ \reg\                   & subtraction                                          &      & zcvn        \\
    \hline
    0011    & \texttt{sub2i}  & \reg\ \const\                 & subtract immediate constant                          & z    & zcvn        \\
    \hline
    0100    & \texttt{cmp}    & \reg\ \reg\                   & comparison                                           &      & zcvn        \\
    \hline
    0101    & \texttt{cmpi}   & \reg\ \const\                 & comparison with immediate constant                   & s    & zcvn        \\
    \hline
    0110    & \texttt{let}    & \reg\ \reg\                   & register copy                                        &      &             \\
    \hline
    0111    & \texttt{leti}   & \reg\ \const\                 & fill register with constant                          & s    &             \\
    \hline
    1000    & \texttt{shift}  & \textit{dir} \reg\ \shiftval\ & logical shift                                        &      & zcn         \\
    \hline
    10010   & \texttt{readze} & \ctr\ \size\ \reg\            & read \size\ memory bits (zero-extended) to \reg\     &      &             \\
    10011   & \texttt{readse} & \ctr\ \size\ \reg\            & read \size\ memory bits (sign-extended) to \reg\     &      &             \\
    \hline
    1010    & \texttt{jump}   & \addr\                        & relative jump                                        &      &             \\
    \hline
    1011    & \texttt{jumpif} & \cond\ \addr\                 & conditional relative jump                            &      &             \\
    \hline
    110000  & \texttt{or2}    & \reg\ \reg\                   & logical bitwise or                                   &      & zcn         \\
    \hline
    110001  & \texttt{or2i}   & \reg\ \const\                 & logical bitwise or                                   & {z}  & zcn         \\
    \hline
    110010  & \texttt{and2}   & \reg\ \reg\                   & logical bitwise and                                  &      & zcn         \\
    \hline
    110011  & \texttt{and2i}  & \reg\ \const\                 & logical bitwise and                                  & {z}  & zcn         \\
    \hline
    110100  & \texttt{write}  & \ctr\ \size\ \reg\            & write the lower \size\ bits of \reg\ to mem          &      &             \\
    \hline
    110101  & \texttt{call}   & \addr\                        & sub-routine call                                     & s    &             \\
    \hline
    110110  & \texttt{setctr} & \ctr\ \reg\                   & store \reg\ to a counter                             &      &             \\
    \hline
    110111  & \texttt{getctr} & \ctr\ \reg\                   & copy the current value of a counter to \reg\         &      &             \\
    \hline
    1110000 & \texttt{push}   & \size\ \reg\                  & push value of register on stack                      &      &             \\
    \hline
    1110001 & \texttt{return} &                               & return from subroutine                               &      &             \\
    \hline
    1110010 & \texttt{add3}   & \reg\ \reg\ \reg\             &                                                      &      & zcvn        \\
    \hline
    1110011 & \texttt{add3i}  & \reg\ \reg\ \const\           &                                                      & z    & zcvn        \\
    \hline
    1110100 & \texttt{sub3}   & \reg\ \reg\ \reg\             &                                                      &      & zcvn        \\
    \hline
    1110101 & \texttt{sub3i}  & \reg\ \reg\ \const\           &                                                      & z    & zcvn        \\
    \hline
    1110110 & \texttt{and3}   & \reg\  \reg\ \reg\            &                                                      &      & zcn         \\
    \hline
    1110111 & \texttt{and3i}  & \reg\ \reg\ \const\           &                                                      & {z}  & zcn         \\
    \hline
    1111000 & \texttt{or3}    & \reg\ \reg\ \reg\             &                                                      &      & zcn         \\
    \hline
    1111001 & \texttt{or3i}   & \reg\ \reg\ \const\           &                                                      & {z}  & zcn         \\
    \hline
    1111010 & \texttt{xor3}   & \reg\ \reg\ \reg\             &                                                      &      & zcn         \\
    \hline
    1111011 & \texttt{xor3i}  & \reg\ \reg\ \const\           &                                                      & {z}  & zcn         \\
    \hline
    1111100 & \texttt{asr3}   & \reg\  \reg\ \shiftval\       &                                                      &      & zcn         \\
    \hline
    1111101 & \texttt{}       &                               & reserved                                             &      &             \\
    \hline
    1111110 & \texttt{}       &                               & reserved                                             &      &             \\
    \hline
    1111111 & \texttt{}       &                               & reserved                                             &      &             \\
    \hline
  \end{tabular}
\end{center}
\end{table}


\begin{table}
  \label{tab:constantes}
  \centering
  \caption{Encodage des constantes}
  \begin{tabular}{|l|l|}
    \hline
    \multicolumn{2}{|c|}{\textit{addr} : Encodage \emph{prefix-free} des adresses et déplacements} \\
    \hline
    0 + 8 bits    & adresse ou déplacement sur 8 bits                                              \\
    \hline
    10 + 16 bits  &                                                                                \\
    \hline
    110 + 32 bits &                                                                                \\
    \hline
    111 + 64 bits &                                                                                \\
    \hline
    \hline
    \multicolumn{2}{|c|}{\textit{shiftval} : Encodage \emph{prefix-free} des constantes de shift}  \\
    \hline
    0 + 6 bits    & constante entre 0 et 63                                                        \\
    \hline
    1             & constante 1                                                                    \\
    \hline
    \hline
    \multicolumn{2}{|c|}{\textit{const} : Encodage \emph{prefix-free} des constantes ALU}          \\
    \hline
    0 + 1 bit     & constante 0 ou 1                                                               \\
    \hline
    10 + 8 bits   & octet                                                                          \\
    \hline
    110 + 32 bits &                                                                                \\
    \hline
    111 + 64 bits &                                                                                \\
    \hline
    \hline
    \multicolumn{2}{|c|}{\textit{size} : Encodage \emph{prefix-free} des tailles mémoire}          \\
    \hline
    00            & 1 bit                                                                          \\
    \hline
    01            & 4 bits                                                                         \\
    \hline
    100           & 8 bits                                                                         \\
    \hline
    101           & 16 bits                                                                        \\
    \hline
    110           & 32 bits                                                                        \\
    \hline
    111           & 64 bits                                                                        \\
    \hline
  \end{tabular}
\end{table}



\subsection{Les instructions de branchement }
\label{sec:jumpcallret}

Soit $a$ l'adresse du premier bit suivant l'instruction \texttt{jump} ou \texttt{call} (i.e. la valeur du PC lorsqu'il a fini de lire l'instruction et ses opérandes).
Soit $d$ la valeur de déplacement (encodée dans une constante de type \textit{addr}, et signée).

L'instruction \texttt{jump} réalise $\mathtt{pc}\leftarrow a + c$.
L'instruction \texttt{jumpif} aussi, mais seulement si la condition est vraie.

La condition  est encodée sur trois bits  selon la table~\ref{tab:conditions}.
\newcommand{\bool}{\mathbb{B}}
\newcommand{\booland}{\wedge}
\newcommand{\boolor}{\vee}
\newcommand{\boolnot}[1]{\overline{#1}}
\begin{table} 
  \caption{Condition codes}
  \label{tab:conditions}
\begin{center}
  \begin{tabular}{|c|c|c||l||l|c|}
    \hline  
      &   &   & mnemonic                  & description (after \texttt{cmp} op1 op2)           & {implem.}                                                                           \\
    \hline  
    \hline  
    0 & 0 & 0 & \texttt{eq}, \texttt{z}   & equal, op1 $=$ op2                                 & $z$                                                                                 \\
    \hline
    0 & 0 & 1 & \texttt{neq}, \texttt{nz} & not equal, op1 $\neq$ op2                          & $\boolnot{z}$                                                                       \\
    \hline
    0 & 1 & 0 & \texttt{sgt}              & signed greater than, op1 $>$ op2, two's complement & $\boolnot{z} \booland (n \booland {v}) \boolor (\boolnot{n} \booland \boolnot{v}) $ \\
    \hline
    0 & 1 & 1 & \texttt{slt}              & signed smaller than, op1 $<$ op2, two's complement & $(n \booland \boolnot{v}) \boolor (\boolnot{n} \booland v) $                        \\
    \hline
    1 & 0 & 0 & \texttt{gt}               & op1 $>$ op2, unsigned                              & $\boolnot{z} \booland \boolnot{c}$                                                  \\
    \hline
    1 & 0 & 1 & \texttt{ge}, \texttt{nc}  & op1 $\ge$ op2, unsigned                            & $\boolnot{c}$                                                                       \\
    \hline
    1 & 1 & 0 & \texttt{lt}, \texttt{c}   & op1 $<$ op2, unsigned                              & $c$                                                                                 \\
    \hline
    1 & 1 & 1 & {\texttt{v}}              & {two's complement overflow}                        & {$v$}                                                                               \\
    \hline
  \end{tabular}
\end{center}
\end{table} 

La différence entre \texttt{sgt} et \texttt{gt} s'observe par exemple sur la comparaison entre \texttt{r0} et -1.

L'instruction \texttt{call} copie $\texttt{a}$ dans $r_{7}$, puis réalise $\mathtt{pc} \leftarrow \texttt{d}$
(c'est un peu bizarre de sauter à des adresses négatives mais du coup \emph{addr} est toujours signé).

L'instruction \texttt{return} copie \texttt{r7} dans \texttt{pc}.

\subsection{Les instructions d'accès mémoire}
\label{sec:mem}



On a 4 compteurs d'adresses, chacun  répliqué dans le processeur et dans la mémoire (Table~\ref{tab:counters}).


Les instructions \texttt{readze}, \texttt{readse} et \texttt{write} lisent ou écrivent le nombre spécifié de bits tout en incrémentant les compteurs correspondant.

On peut émuler une instruction de lecture/écriture mémoire d'un processeur classique en deux instructions: un \texttt{setctr} puis un \texttt{readze} ou \texttt{readse} ou \texttt{write}.

Les instructions \texttt{push} et \texttt{pop} implémentent une pile descendante en mémoire: 
\begin{itemize}
\item \texttt{push} \emph{size} \emph{reg} réalise: \\
  $\mathit{sp}\leftarrow \mathit{sp}-\mathit{size}$\\ \texttt{setctr} \textit{sp}\\ \texttt{write}  \textit{sp} \textit{size} \textit{reg} \\   $\mathit{sp}\leftarrow \mathit{sp}-\mathit{size}$\\ \texttt{setctr} \textit{sp}
\item \texttt{pop} \emph{size} \emph{reg} est un raccourci offert par l'assembleur pour \\\texttt{readze} \textit{sp} \emph{size} \emph{reg}\\
  
\end{itemize}

\begin{table} 
  \caption{Counters. Ces deux bits sont transmis sur le signal \texttt{Select} de la figure~\ref{fig:overview}. }
  \label{tab:counters}
\begin{center}
  \begin{tabular}{|l|l|l|}
    \hline  
  encoding  & mnemonic & description \\
    \hline  
    \hline  
    00& \texttt{pc} &  program counter\\
    \hline
    01& \texttt{sp} & stack pointer\\
    \hline
    10& \texttt{a0} &  generic address counter\\
    \hline
    11& \texttt{a1} &  generic address counter\\
    \hline
  \end{tabular}
\end{center}
\end{table}


\section{Expériences}

Pour une petite suite de benchmarks (écrits en assembleur à la main puisque nous n'avons pas encore de compilateur pour cette architecture), nous avons réalisé les mesures suivantes.

La première expérience consiste à utiliser l'encodage initial.
Des compteurs, dans le simulateur, mesurent l'utilisation de chaque instruction (rapportée dans la table~\ref{tab:opcounts}. \todo{Il faut choisir quelle instruction on rapporte}
D'autres compteurs comptent les bits échangés sur les fils à l'exécution.
Les résultats correspondants sont donnés dans la première  ligne pour chaque benchmark dans la table~\ref{tab:bitcounts}.

La seconde expérience (dont es résultats sont donnés sur la seconde ligne pour chaque benchmark dans la table~\ref{tab:bitcounts}) donne les valeurs obtenues lorsque le même programme utilise un encodage de Hufmann optimal \emph{pour ce benchmark}.
Cet encodage utilise les statistiques de la table~\ref{tab:opcounts}.
Bien sûr, cette seconde expérience reviendrait à construire un processeur optimisé pour chaque benchmark, ce qui n'est pas déontologique: l'intérêt de cette seconde expérience est de donner une borne inférieure au nombre de bits échangés pour chaque benchmark. 

\begin{table}
  \centering
  \begin{tabular}{|c||c|c|c|c|}
    \hline
    benchmark & add2i & .... &  \\
    \hline
    \hline
  \end{tabular}
  \caption{Pourcentage d'utilisation de quelques instructions}
  \label{tab:opcounts}
\end{table}




\begin{table}
  \centering
  \begin{tabular}{|c||c|c||c|c|}
    \hline
    benchmark    & taille du programme & bit/instr. & \multicolumn{2}{c|}{bits échangés à l'exec.} \\
                 &                     &            & programme & données                         \\
    \hline
    \hline
    binmult,init &                     &            &           &                                 \\
    binmult, opt &                     &            &           &                                 \\
        \hline
  \end{tabular}
  \caption{Nombre de bits échangés par benchmark}
  \label{tab:bitcounts}
\end{table}

\section{Améliorations et pistes d'améliorations}

Le coût intéressant de cette étude est le nombre de bits échangés sur les fils de données. On distinguera trois types de données échangées : 
\begin{enumerate}
\item les instructions du programme (code lu par le processeur).
\item les données explicitement lues ou écrites (à l'aide de \texttt{readze}, par exemple)
\item Les bits d'adresses (typiquement, l'affectation de compteurs)
\end{enumerate}

Par exemple, \texttt{jump 0x1f68} va être lue par le processeur : $4$ bits plus $18$ bits (une constante sur $16$ bits), puis pc + \texttt{0x1f68} va être écrit dans le pc, $64$ bits vont donc transiter. On a donc un total de $22$ bits d'instruction, $0$ bit de données et $64$ bits de compteurs.
La table \ref{tab:costs} résume le coût de chaque opération.

\subsection{Combien de registres ?}
Le nombre de registres est un compromis entre le nombre d'accès à la pile en mémoire et la taille des instructions :
d'un côté, doubler le nombre de registres demande d'ajouter un sinon deux bits à presque toutes les instructions;
de l'autre, avoir trop peu de registres oblige à utiliser plus fréquemment la mémoire.
En survolant les processeurs existant, on peut {\it a priori} considérer que $4$ registres rend le processeur impraticable, et que $16$ est sufisamment confortable pour programmer.
Le choix de 8 est en partie pédagogique: il s'agissait de pouvoir écrire nos premiers programmes assembleur avec assez de registres pour être confortable, et toutefois d'être contraint dès que les programmes deviennent un peu plus gros. 
Avec huit registres, et pas mal d'astuce (par exemple, comment échanger deux registres sans utiliser de registre intermédiaire ?), les élèves s'en sont sortis avec des statistiques de \emph{spill} mémoire raisonnables (inférieures à 1\% des instructions).
Toutefois, une vraie réponse à cette question demande de faire une étude qui couvre également (et surtout) la problématique de la compilation.
% 
% On peut donc espérer avec un \texttt{push} efficace un gain optimal avec seulement 8 registres. 
Il faudrait voir également si un système de fenêtre de registres comme sur le SPARC ne permettrait pas de réduire la quantité de bits d'instruction servant à encoder les registres.
% Cette section fait l'hypothèse que 

\subsection{Modes d'adressage mémoire}
\subsection{Bits de compteurs}
\subsubsection{choix initiaux}
On a fait le choix de ne pas faire d'adressage par registre : en effet, cela aurait coûté 64 bits d'adresse par adressage. Les compteurs permettent de faire autant avec seulement 2 bits à chaque adresse. En contrepartie, l'arithmétique sur les pointeurs devient extrêmement coûteuse : charger une adresse dans un registre ; faire une opération arithmétique ; affecter l'adresse avec le registre. Cependant, on espère que la plupart du temps, les données sont lues de manière séquencielle, et que donc un adressage avec post-incrément suffit à limiter l'arithmétique des pointeurs.\par
Cette affirmation est à relativiser : par exemple, le pc lit les données séquentiellement la plupart du temps. De même, dans les expériences, un écran avait été mappé sur la mémoire, et on pouvait l'effacer en écrivant plusieurs fois \texttt{0x0} à son adresse. Cependant, un contre-exemple très souvent utilisé est le \texttt{push}, qui nécessite un pré-decrément (le post-incrément oblige à affecter deux fois \texttt{sp}) ou encore la multiplication de matrices, gourmande en compteurs.
\subsubsection{améliorations}
La première amélioration, proposée dès le départ est de conserver une copie de chaque compteur dans le processeur. Ainsi, les échanges de bits de compteurs ne sont nécessaires que pour synchroniser les compteurs du processeur et de la mémoire : \texttt{getctr} ne coûte plus aucun bit de compteur, on a aussi un gain sur le \texttt{push}
Ensuite, lors d'une affectation de compteurs, on n'est pas obligé d'écrire tous les bits s'ils sont envoyés poids faible d'abord. Si on envoie $n\leqslant 64$ bits à la mémoire, la mémoire peut écrire ces $n$ bits et remplire les $64-n$ autres avec des zéros. Cela diminuerait grandement le coût des affectations du pc, très proche du début de la mémoire (le code est stocké en \texttt{0x0}). Une autre idée, plus générale, serait de ne pas toucher aux $64-n$ derniers bits. On aurait un gain lors d'affectations proches en mémoire (même si bien sûr on ne peut rien garantir : \texttt{0x1000000 - 0x1 = 0xffffff})\par
Une autre amélioration, non-implémentée, serait d'ajouter des instructions d'incrémentation des compteurs par un registre ou une constante. On remplacerait les trois instructions \texttt{getctr a0 r0 ; add2 r0 r1 ; setctr a0 r0} par l'unique \texttt{incrctr a0 r0}. Si on ne gagne pas sur le nombre de bits de compteurs échangés (toujours $64$), cette instruction est assez facile à implanter en machine, on factorise un trio d'instruction assez présent dans la boucle interne de nombreux programmes (par exemple la multiplication matricielle) en une seule, et on gagne un registre.

\subsubsection{les adresses de jump}

\subsubsection{le problème de la pile}
Si avec le post-incrément, le \texttt{pull} ne coûte rien, dans la version naïve, le push est extrêmement coûteux : \texttt{push 32 r0} fait d'abord transiter $7$ bits de la mémoire au processeur pour l'opérande, $3$ pour le registre. L'instruction est lue. Il faudra ensuite faire reculer le pointeur de pile de $32$ bits : $64$ bits pour récupérer \texttt{sp}, $64$ autres pour l'affecter. Les $32$ bits de \texttt{r0} sont écrits, puis on fait de nouveau reculer le pointeur de pile : $64$ bits. Soit un total d'instructions lues de $10$, $32$ bits de lus, et $192$ bits de compteurs.\par
C'est un problème : comme on l'a vu l'efficacité du \texttt{push} détermine la quantité de registres nécessaire. La première amélioration proposée permet de faire descendre le coût du \texttt{push} à 128 bits, et plus si on décide d'un endroit adéquat pour placer le fond de la pile. Cependant, un gain énorme serait d'autoriser l'écriture avec pré-décrément : en écrivant les bits un à un à l'envers et en pré-décrément sur sp, on n'a plus besoin d'affecter sp. Le nombre de bits d'adresse dus au push retomberait à 0. Une manière assez simple de l'implémenter et de faire transiter le sens d'écriture sur le fil \texttt{Read} : 0 indiquerait post-incrément, et 1 pré-décrément. On pourrait même alors imaginer un \texttt{push} prenant en argument un compteur. Ainsi, chaque compteur pourrait devenir une pile.

\begin{table}[!h]
  \caption{Coûts des opérations}
  \label{tab:costs}
  On propose une première version naïve du coût de chaque opération, pour une architecture 64 bits. La taille de l'opcode d'une instruction étant variable, il faut à chaque fois l'ajouter dans les instructions lues.
  \begin{center}
  \begin{tabular}{|l|c|c|c|}
    \hline  
    type  & bits d'instruction & bits de données & bits de compteurs \\
    \hline  
    \hline
    \texttt{arith} \reg\ \reg\ &  $6$ & & \\
    \hline
    \texttt{arith} \reg\ \reg\ \reg\ & $9$ & & \\
    \hline
    \texttt{arith} \reg\ \const\ & $3$ + \const & & \\
    \hline
    \texttt{arith} \reg\ \reg\ \const\ & $6$ + \const & & \\
    \hline
    \texttt{r/w} \ctr\ \size\ \reg & $2$ + \size\ + $3$ & \size & \\
    \hline
    \texttt{get-,setctr} \ctr\ \reg\ & $2$ + $3$ & & $64$ \\
    \hline
    \texttt{jump} & \addr\ & & $64$ \\
    \hline
    \texttt{jumpif} \cond & $3$ + \addr\ & & $0$ ou $64$\\
    \hline
    \texttt{call} \addr & \addr\ & & $64$\\
    \hline
    \texttt{return} & & & $64$\\
    \hline
    \texttt{push} \size\ \reg & $3$ & \size & $192$\\
    \hline
  \end{tabular}
  \end{center}
Après améliorations, on arrive à ce nouveau tableau :
  \begin{center}
    \begin{tabular}{|l|c|c|c|}
      \hline  
      type  & instructions lues & données lues/écrites & compteurs \\
      \hline  
      \hline
      \texttt{getctr} \ctr\ \reg\ & $2$ + $3$ & & \\
      \hline
      \texttt{setctr} \ctr\ \reg\ & $2$ + $3$ & & $\leqslant 64$ \\
      \hline
      \texttt{jump} & \addr\ & & $\leqslant 64$ \\
      \hline
      \texttt{jumpif} \cond & $3$ + \addr\ & & $0$ ou $\leqslant 64$\\
      \hline
      \texttt{call} \addr & \addr\ & & $\leqslant 64$\\
      \hline
      \texttt{return} & & & $\leqslant64$\\
      \hline
      \texttt{push} \size\ \reg & $3$ & \size &\\
      \hline
    \end{tabular}
  \end{center}
\end{table}

\section{Conclusion et perspectives}

- une étude de l'encodage d'un jeu d'instruction universel si l'on enlève la contrainte de la taille des codes

- quel réalisme et quelles applications

- un processeur dont l'encodage est reconfigurable? 
\bibliography{biblio.bib}

\end{document}
