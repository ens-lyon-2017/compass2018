\documentclass[architecture]{compas2018}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\toappear{1} % Conserver cette ligne pour la version finale

\usepackage{tikz}
\tikzset{
  hwblock/.style={draw, rectangle, rounded corners=.3, very thick, fill=black!5, font=\sf, minimum height=5ex},
  hwbus/.style={very thick,>=stealth},
  hwwire/.style={thin, >=stealth, },
  hwword/.style={draw, rectangle, minimum height=3ex},
  bitwidth/.style={font=\scriptsize,midway,right}
}

\newcommand{\reg}{\textit{reg}}
\newcommand{\const}{\textit{const}}
\newcommand{\shiftval}{\textit{shiftval}}
\newcommand{\cond}{\textit{cond}}
\newcommand{\ctr}{\textit{ctr}}
\newcommand{\size}{\textit{size}}
\newcommand{\addr}{\textit{addr}}

\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}
\begin{document}

\title{Une architecture minimisant les échanges\\ entre processeur et mémoire}

\author{Florent de Dinechin, \\Sébastien Michelland, Maxime Darrin, Antonin Dudermel, Alban Reynaud}

\address{
  % \begin{tabular}{cc}
  %   ENS-Lyon & INSA Lyon \\
  %   \texttt{nom.prenom@ens-lyon.org} \\
  % \end{tabular}
}

\date{\today}

\maketitle
\sloppy

\begin{abstract}
Dans une architecture de von Neumann, le processeur communique avec la mémoire au moyen d'un bus d'adresses et d'un bus de données de grandes tailles (entre 16 et 64 bits).
C'est une contrainte pour l'encodage des instructions du processeur, comme le montre un survol historique des jeux d'instruction dominants.
Or les échanges de données représentent le gros de l'énergie dépensée.
Cet article fait l'exercice de lever cette contrainte, dans le but de minimiser le nombre de bits échangés entre le processeur et la mémoire.
Il décrit une architecture 64 bits dont la mémoire est adressable par bit, avec un seul signal de données entre le processeur et la mémoire.
Ceci permet d'avoir des instructions de taille arbitraire.
Pour ne pas devoir envoyer une adresse complète à la mémoire à chaque accès, la solution proposée est l'usage de pointeurs auto-incrémentés dupliqués dans la mémoire et le processeur.

Cet article décrit aussi une expérience pédagogique réalisée à l'ENS-Lyon (ce qui explique en partie certains choix simplistes).
Un premier jeu d'instruction a été défini en TD et son encodage choisi à la main.
Ceci a permis aux étudiants d'écrire en binôme un assembleur et un simulateur, puis plusieurs milliers de lignes de programmes allant du petit noyau de calcul au jeu vidéo et à l'émulateur.
Sur les traces de ces programmes, on a pu ensuite calculer un encodage optimal des instructions des instructions en fonction de leur fréquence via des arbres de Huffmann, et les comparer à l'encodage initial.
On arrive à une taille moyenne d'instruction entre 9 et 15 bits suivants les programmes.
 Ces expérimentations montrent aussi que le code représente une part importante des données transitant entre processeur et mémoire. 
 L'article discute enfin les limites de cette approche, et d'éventuelles solutions pour y remédier.
\end{abstract}

%=========================================================
\section{Introduction et motivation}
% =========================================================
Cet article s'intéresse à l'encodage du jeu d'instruction d'un processeur de von Neumann, interfacé à une mémoire par un bus d'adresse et un bus de données comme schématisé sur la figure~\ref{fig:mvn}.

\newcommand{\figVonNeumann}{
  \begin{tikzpicture}
    \node[hwblock, minimum width=15ex,minimum height=15ex] (p) at (0,0)  {Processeur} ;
    \node[hwblock, minimum width=15ex,minimum height=15ex] (m) at (30ex,0)  {Mémoire} ;
    \draw[hwbus,->] (p.25) -- (m.155) node[midway,above=1ex]{adresse} node[midway]{/} node[midway, below right]{$w_a$};
    \draw[hwbus,<->] (p.335) -- (m.205) node[midway,below]{données} node[midway]{/} node[midway, above left]{$w_d$};
  \end{tikzpicture}
}

\begin{figure}[ht]
  \begin{center}
    \figVonNeumann
  \end{center}
  \caption{Une machine de von Neumann.}
  \label{fig:mvn} \index{von Neumann}\index{machine de von Neumann}
\end{figure}

\subsection{Généralités}
Le jeu d'instruction d'un processeur (Instruction Set Architecture ou ISA) reflète l'état de la loi de Moore à l'époque de sa conception.
Celle-ci se traduit par exemple par un doublement de la quantité de mémoire intégrée sur une puce tous les deux ans.
Comme il faut bien adresser cette mémoire, le bus mémoire suit, et sa taille ($w_a$ sur la figure) grandit donc d'un bit tous les deux ans.
Ceci se traduit à son tour par une croissance de la taille des registres qui, dans un processeur, peuvent adresser la mémoire.
Toutefois, ici, le fétichisme des architectes pour les puissances de 2 intervient, et on a observé une croissance de ces registres par palier: de 8 bits aux temps héroïques à 16 bits dans les années 70, 32 bits dans les années 80, et 64 bits dans les années 2000.
Les adresses sur 64 bits devraient ainsi suffire pour plusieurs dizaines d'années, mais l'on se gardera bien de faire des pronostics si lointains.

\iffalse % c'est fort intéressant mais on s'en fout
La croissance du bus de données a suivi avec du retard, pour plusieurs raisons.
La première est que la loi de Moore doit aussi fournir assez de transistors au processeur pour calculer sur des données de plus en plus grandes.
Mais la complexité des principales opérations d'un processeur travaillant sur $n$ bits est en $n$, en $n\log n$ ou au pire en $n^2$: si l'on a pu être à l'étroit jusque dans les années 90 pour construire un processeur qui peut calculer sur des adresses mémoires, ce n'est plus le cas depuis.
La seconde raison est que les ordinateurs servent beaucoup à travailler sur du texte, donc des octets.
On a donc vu des processeurs très populaires 8/16 bits, c'est à dire $w_d=8$ et  $w_a = 16$: les z80, 6502, 8088; des processeurs 16/32 bits (68000, 80286 à 486); et même une variante 8/32 bits, le 68008. Puis l'industrie a convergé vers 32/32 avec l'arrivée des processeurs RISC  (SPARC,  ARM et Power)  puis et 64/64 avec AMD64 et ARM64.
Ainsi,  
De nos jours, les processeurs ont des registres de plusieurs centaines de bits (AMD64 SSE* puis AVX*, ARM Neon), encore une fois parce que la loi de Moore le permet.
Mais ces registres sont des vecteurs de données d'au plus 64 bits.
\fi



Une question intéressante, et qui commence à toucher le jeu d'instruction, est l'adressabilité, c'est-à-dire la granularité à laquelle on peut adresser la mémoire.
L'ancêtre 4004 adressait sa mémoire par cases de 4 bits, ce qui correspondait au besoin du décimal codé en binaire. Le processeur Saturn des calculettes HP était aussi un processeur 4/20 bits.
La plupart des processeurs (dont les Intel/AMD de nos PC et les ARM de nos gadgets) adressent leur mémoire par octet pour être efficace sur le traitement de texte.

Cela dit, dans un processeur 32 bits, les données de 32 bits doivent avoir des adresses dites alignées, c'est à dire multiples de 4 octets. Un accès non aligné se traduit selon les ISA par une faute ou par un accès beaucoup plus lent.


\subsection{Pourquoi pas l'adressabilité au bit près?}
Ceci nous amène à la première constatation. Dès lors que les adresses font 64 bits, on peut parfaitement décider  que le adresses seront des adresses de bits.
On perd un facteur 8 en quantité de mémoire adressable.
Ce qui aurait été inacceptable à l'époque des adresses sur 16 bits est indolore pour quelques années avec un espace d'adressage sur 64 bits: il reste tout de même $2^{61}\approx 2.10^{18}$ bits, ou 2 exabits, à adresser.


Attention, on parle de l'abstraction offerte par le jeu d'instruction, pas de l'interface physique.
Les deux sont déjà différentes dans les processeurs actuels.
Dans le jeu d'instruction AMD64, l'ISA définit une mémoire adressable par octet, avec des contraintes d'alignements pour les accès à des données plus grandes.
Par contre l'accès physique à la mémoire se fait à travers un cache qui, côté processeur, offre l'adressage par octet, mais côté mémoire physique  réalise des accès alignés sur une grande puissance de 2 correspondant à la taille de la ligne de cache.

Certes, passer d'un adressage par octet à un adressage au bit complique légèrement l'interface processeur-cache.
On peut estimer que cela ajoute trois niveaux de multiplexeurs au décodage de la ligne de cache, un changement plus quantitatif que qualitatif.
Cela dit, dans tout cet article nous ignorons sereinement cette problématique.
Nous ne remettrons les pieds sur terre que dans la discussion de conclusion.


Mais que gagne-t-on à avoir une adresse pour chaque bit?  On peut manipuler des données au bit près.
Surtout, la tailles des données peut être variable au bit près.
Comme exemple d'application, on peut citer les UNUM, un format de représentation des nombres flottants de taille variable et auto-descriptif (les tailles d'exposant et de mantisse sont encodées dans un en-tête) proposé par  Gustafson en 2015 \cite{2015-02-GUSTAFSON}.
Cette proposition est déjà abandonnée par son auteur \cite{2016-09-TICHY} malgré quelques bonnes idées, mais une de ses principales motivations reste: les transferts de données sont extrêmement coûteux.
D'après Dally, en technologie 28nm, le calcul d'une multiplication-addition flottante sur des données 64 bits coûte 50pJ, et l'accès aux registres sur puce est du même ordre de grandeur, alors qu'une lecture de 64 bits de la DRAM coûte 4000pJ.
\todo{F2D: citation}

Il y a aussi des applications, comme les réseaux de neurones, qui se contentent très bien de données sur de très petites précision, voire des données binaires \cite{AndriCRB16,AlemdarEtAl2017:TernaryCNN,AmiriEtAl2018:mixedPrecCNN,Preusser:DATE2018:heteroCNN}. 

\subsection{Pourquoi pas un jeu d'instruction au bit près?}

Les jeux d'instructions les plus compacts à notre connaissance sont les \emph{bytecodes} des machines virtuelles comme Java ou Python, qui émulent une machine à pile.
\todo{F2D}

\subsection{Contexte de ce travail}
Résumé des objectifs pédagogiques du cours ASR1

\todo{F2D}
\subsection{Plan}

\todo{F2D}



\section{Architecture générale et interface mémoire}
Pour donner une interface simple à l'adressabilité au bit près, nous proposons une interface processeur-mémoire strictement série représentée sur la figure~\ref{fig:overview}.
Les données passent en série, bit à bit, sur le fil \texttt{D}.
Le processeur contrôle le sens de transfert par les fils \texttt{Read} et \texttt{Write}.
Pour ne pas avoir à transmettre une adresse de $n$ nbits par bit de donnée, les adresses sont le plus souvent implicites.
Dans ce but, on a 4 compteurs, répliqués dans le processeur et la mémoire.
Par exemple le pointeur de programme, PC, est l'un de ces compteurs.
Pour lire une donnée, le processeur sélectionne un des compteurs en positionnant les deux bits  \texttt{Select}.
Puis il lève \texttt{Read}.
Tant que \texttt{Read} vaut 1, le compteur sélectionné s'incrémente (côté processeur comme côté mémoire) et les bits qu'il pointe sont transférés sur le fil \texttt{D}.
Lorsque le processeur décide qu'il a lu toute une donnée, il baisse \texttt{Read}.

Ce mécanisme fonctionne de manière similaire en cas d'écriture.
Il faut naturellement des instructions qui permettent de changer les compteurs: pour cela le processeur lève \texttt{SetCounter}, puis transfère sur \texttt{D} les bits du compteur selectionné par \texttt{Select}, poids faible en tête.
Lorsque le processeur baisse \texttt{SetCounter}, la mémoire complète le compteur avec le dernier bit transmis (extension de signe).

Un intérêt de cette interface est qu'elle ne dépend pas ni de la taille mémoire, ni de la puissance du processeur (elle est identique pour un processeur 32 ou 64 bits).
\begin{figure}[h]
    \begin{center}
  \begin{tikzpicture}
    \node[hwblock, minimum width=25ex,minimum height=25ex] (p) at (-10ex,0)  {~~~Processor} ;
%    \draw  (p) ++(0,-10ex)  node {} ;
    \node[hwblock, minimum width=25ex,minimum height=25ex, align=center] (m) at (30ex,0)  {Serial\\ Memory} ;
    
    \draw (p.north west)  ++(4ex,-3ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{PC} ;
    \draw (p.north west)  ++(4ex,-7ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{SP} ;
    \draw (p.north west)  ++(4ex,-11ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A0} ;
    \draw (p.north west)  ++(4ex,-15ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A1} ;
    
    \draw (m.north east)  ++(-4ex,-3ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{PC} ;
    \draw (m.north east)  ++(-4ex,-7ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{SP} ;
    \draw (m.north east)  ++(-4ex,-11ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A0} ;
    \draw (m.north east)  ++(-4ex,-15ex)  node[hwblock,minimum height=3ex,minimum width=5ex]{A1} ;

    \draw[hwwire,<->] (p.35) -- (m.145) node[midway,above]{\texttt{D}};

    \draw[hwwire,->] (p.10) -- (m.170) node[midway,above]{\texttt{Read}};
    \draw[hwwire,->] (p.355) -- (m.185) node[midway,above]{\texttt{Write}};
    \draw[hwwire,->] (p.340) -- (m.200) node[midway,above]{\texttt{SetCounter}};
    \draw[hwwire,->] (p.322) -- (m.218) node[midway,above]{\texttt{Select}};
    \draw[hwwire,->] (p.320) -- (m.220) node[midway,above]{};
    \draw[hwwire,<-] (m.south) -- ++(0,-4ex) -- ++(-50ex,0) node[left]{\texttt{Ck}};
    \draw[hwwire,<-] (p.south) -- ++(0,-4ex);
    \draw[hwwire,-] (p.south)  ++(-1ex, 0) -- ++(1ex,1ex) -- ++(1ex,-1ex); % horloge
    \draw[hwwire,-] (m.south)  ++(-1ex, 0) -- ++(1ex,1ex) -- ++(1ex,-1ex); % horloge
  \end{tikzpicture}
  \end{center}
  \caption{L'interface processeur-mémoire proposée}
  \label{fig:overview}
\end{figure}

\subsection{Comparaison avec une architecture classique}
Si l'on compare la figure~\ref{fig:overview} avec la figure~\ref{fig:mvn} lors de l'exécution d'un programme classique, il est clair que notre proposition dégrade le temps d'exécution, puisque la transmission de la moindre instruction et la moindre donnée demandent plusieurs cycles d'horloge.

Si par contre on s'intéresse aux nombre de transitions sur les fils (une métrique raisonnable pour mesurer la consommation dynamique), on peut faire les observations suivantes.

\begin{itemize}
\item Dans la lecture de données consécutives en mémoire, notre proposition fait l'économie de toutes les transitions sur le bus d'adresse.
  En particulier, la lecture des instructions d'un programme, en dehors des branchements,  ne demande aucune transmission d'adresse.
\item Adresses comme données peuvent être transmises au bit près.
\item Par contre on a une transition d'horloge par bit transmis, au lieu d'une transition d'horloge pour $w_a$ ou $w_d$ bits.
\end{itemize}
Il y a donc un potentiel de réaliser moins de transitions avec le système proposé, potentiel que le présent article se propose de mesurer.

Pour cela nous nous efforçons principalement de minimiser la taille de l'encodage du jeu d'instructions.

\subsection{un c\oe ur  RISC}
Pour le reste, le processeur embarque un c\oe ur RISC très classique, d'architecture load/store, à 8 registres 32 ou 64 bits.  
Le choix de 8 registres seulement est arbitraire et discutable: il est motivé par des raisons pédagogiques (faire en sorte que les étudiants soient à l'étroit dans les registres  dès l'écriture de programmes simples) et par une raison pratique (encoder le numéro de registre sur aussi peu de bits que possible).
Il est rediscuté en \ref{sec:amelioration}. 









\section{Présentation du jeu d'instruction initial}
Le jeu d'instruction décrit dans cette section est l'aboutissement de deux séances de TD dans lesquelles on a essayé de discuter les tenants et les aboutissants de chaque décision.
Les choix faits ne sont pas toujours ceux qui étaient considérés les meilleurs: nous avons aussi privilégié la faisabilité dans le temps limité consacré au module d'ASR1.


% \subsection{Généralités sur les jeux d'instructions}
% Les jeux d'instructions les plus compacts à notre connaissance sont les \emph{bytecodes} des machines virtuelles comme Java ou Python, qui émulent une machine à pile.
% \todo{blabla}

\subsection{Format général des instructions}
Les instructions commencent toutes par un code opération (opcode), suivi des éventuels opérandes.
Les mnémoniques sont écrits exactement dans le même ordre (voir la figure~\ref{fig:exempleasm}).  
Une fois que le processeur a reçu l'opcode, il sait combien d'opérande il doit recevoir et quel est leur type.


Les instructions ALU viennent en version 2 et 3 opérandes, la destination venant toujours en premier.
Par exemple, \\
  \begin{tabular}{lcl}
 \texttt{add2 r0 r1}&& réalise $r_0 \leftarrow r_0+r_1$. \\
 \texttt{add3 r0 r1 r2}&& réalise $r_0 \leftarrow r_1+r_2$.
  \end{tabular}
  Dans les programmes écrits à la main, il faut constater qu'on a utilisé surtout les versions à 2 opérandes.
  Ceci est similaire à l'évolution du jeu d'instruction ARM vers le mode Thumb2 qui permet d'encoder sur 16 bits des instructions à deux opérandes. 
  
 L'opcode est différent pour les opérations dont les deux opérandes  sont des registres (par exemple \texttt{add2}), et les opérations portant sur un registre et une constante (par exemple \texttt{add2i}).

Il y a des opcodes de différentes tailles (mais sans préfixe commun, le décodage n'est jamais ambigu)  et les opérandes peuvent également être de différentes tailles.
En particulier, les constantes commencent par un préfixe qui décrit le nombre de bits sur lequel est encodé la constante: voir la table~\ref{tab:constantes} en annexe.
Ainsi les petites constantes courantes comme 0 et 1 sont encodées sur peu de bits, alors que les grandes constantes son également encodables.
Pour les sauts relatifs, on paiera moins cher les sauts proches (jusqu'à +/- 128 bits, soit une dizaine d'instructions) que les sauts plus distants, qui sont par définition pris moins fréquemment.

On a un encodage différent pour les constantes pour différentes classes d'instructions (table~\ref{tab:constantes}), puisque les besoins ne sont pas les même.

\begin{figure}
  \centering
\begin{verbatim}
  let r0 17         ; 0111 000 1000010001 ; 000 encode r0,  17 est encodé sur 10 bits
boucle:	                                  ; ceci est une étiquette (label)
  sub2i r0 1        ; 0011 000 01         ; 000 encode r0, 01 encode la constante 1
  jumpif nz boucle  ; 1011 001 011100111  ; jumpif nz -25, encodé en 16 bits en tout 
\end{verbatim}
  \caption{Un exemple de programme assembleur, (une boucle vide) avec son encodage initial}
  \label{fig:exempleasm}
\end{figure}


Les instructions de branchement sont relativement classiques.

\iffalse
\subsection{Les instructions de branchement }
\label{sec:jumpcallret}

Soit $a$ l'adresse du premier bit suivant l'instruction \texttt{jump} ou \texttt{call} (i.e. la valeur du PC lorsqu'il a fini de lire l'instruction et ses opérandes).
Soit $d$ la valeur de déplacement (encodée dans une constante de type \textit{addr}, et signée).

L'instruction \texttt{jump} réalise $\mathtt{pc}\leftarrow a + c$.
L'instruction \texttt{jumpif} aussi, mais seulement si la condition est vraie.

La condition  est encodée sur trois bits  selon la table~\ref{tab:conditions} (ARM utilise 4 bits).

L'instruction \texttt{call} copie $\texttt{a}$ dans $r_{7}$, puis réalise $\mathtt{pc} \leftarrow \texttt{d}$
(\emph{addr} est toujours signé).

L'instruction \texttt{return} copie \texttt{r7} dans \texttt{pc}.

\fi

\subsection{Les instructions d'accès mémoire}
\label{sec:mem}



On a 4 compteurs d'adresses, chacun  répliqué dans le processeur et dans la mémoire (Table~\ref{tab:counters}).


Les instructions \texttt{readze}, \texttt{readse} et \texttt{write} lisent ou écrivent le nombre spécifié de bits tout en incrémentant les compteurs correspondant.

On peut émuler une instruction de lecture/écriture mémoire d'un processeur classique en deux instructions: un \texttt{setctr} puis un \texttt{readze} ou \texttt{readse} ou \texttt{write}.

Les instructions \texttt{push} et \texttt{pop} implémentent une pile descendante en mémoire: 
\begin{itemize}
\item \texttt{push} \emph{size} \emph{reg} réalise: \\
  $\mathit{sp}\leftarrow \mathit{sp}-\mathit{size}$\\ \texttt{setctr} \textit{sp}\\ \texttt{write}  \textit{sp} \textit{size} \textit{reg} \\   $\mathit{sp}\leftarrow \mathit{sp}-\mathit{size}$\\ \texttt{setctr} \textit{sp}
\item \texttt{pop} \emph{size} \emph{reg} est un raccourci offert par l'assembleur pour \\\texttt{readze} \textit{sp} \emph{size} \emph{reg}\\
  
\end{itemize}


\section{Expériences}

Pour une petite suite de benchmarks (écrits en assembleur à la main puisque nous n'avons pas encore de compilateur pour cette architecture), nous avons réalisé les mesures suivantes.

La première expérience consiste à utiliser l'encodage initial.
Des compteurs, dans le simulateur, mesurent l'utilisation de chaque instruction (rapportée dans la table~\ref{tab:opcounts}. \todo{Il faut choisir quelle instruction on rapporte}
D'autres compteurs comptent les bits échangés sur les fils à l'exécution.
Les résultats correspondants sont donnés dans la première  ligne pour chaque benchmark dans la table~\ref{tab:bitcounts}.

La seconde expérience (dont es résultats sont donnés sur la seconde ligne pour chaque benchmark dans la table~\ref{tab:bitcounts}) donne les valeurs obtenues lorsque le même programme utilise un encodage de Hufmann optimal \emph{pour ce benchmark}.
Cet encodage utilise les statistiques de la table~\ref{tab:opcounts}.
Bien sûr, cette seconde expérience reviendrait à construire un processeur optimisé pour chaque benchmark, ce qui n'est pas déontologique: l'intérêt de cette seconde expérience est de donner une borne inférieure au nombre de bits échangés pour chaque benchmark. 

\begin{table}
  \centering
  \begin{tabular}{|c||c|c|c|c|}
    \hline
    benchmark & add2i & .... &  \\
    \hline
    \hline
  \end{tabular}
  \caption{Pourcentage d'utilisation de quelques instructions}
  \label{tab:opcounts}
\end{table}

\texttt{binmult} est un programme qui réalise une multiplication d'entiers non signés 64 bits par additions et décalages. Le programme fait 104 bits dont 69 pour le coeur de boucle


\begin{table}
  \centering
  \begin{tabular}{|c||c|c|c||c|c|c|c|c||c|}
    \hline
    & \multicolumn{3}{c||}{taille du programme} & \multicolumn{6}{c|}{bits échangés à l'exec.}                    \\
    \hline

    
    benchmark    & instr & bits & bpi  & prog   & data R & data W & counters & branch & total \\
    \hline
    \hline
    binmult,init & 10    & 136  & 13,6 & 89,4\% &        &        &          & 10,6\% & 415   \\
    binmult, opt &       &      &      &                                                      \\
        \hline
    \hline
    binmult,init &       &      &      &                                                      \\
    binmult, opt &       &      &      &                                                      \\
        \hline
  \end{tabular}
  \caption{Nombre de bits échangés par benchmark}
  \label{tab:bitcounts}
\end{table}

\section{Améliorations et pistes d'améliorations \label{sec:amelioration}}

Le coût intéressant de cette étude est le nombre de bits échangés sur les fils de données. On distinguera trois types de données échangées : 
\begin{enumerate}
\item les instructions du programme (code lu par le processeur).
\item les données explicitement lues ou écrites (à l'aide de \texttt{readze}, par exemple)
\item Les bits d'adresses (typiquement, l'affectation de compteurs)
\end{enumerate}

Par exemple, \texttt{jump 0x1f68} va être lue par le processeur : $4$ bits plus $18$ bits (une constante sur $16$ bits), puis pc + \texttt{0x1f68} va être écrit dans le pc, $64$ bits vont donc transiter. On a donc un total de $22$ bits d'instruction, $0$ bit de données et $64$ bits de compteurs.
La table \ref{tab:costs} résume le coût de chaque opération.

\subsection{Combien de registres ?}
Le nombre de registres est un compromis entre le nombre d'accès à la pile en mémoire et la taille des instructions :
d'un côté, doubler le nombre de registres demande d'ajouter un sinon deux bits à presque toutes les instructions;
de l'autre, avoir trop peu de registres oblige à utiliser plus fréquemment la mémoire.
En survolant les processeurs existant, on peut {\it a priori} considérer que $4$ registres rend le processeur impraticable, et que $16$ est sufisamment confortable pour programmer.
Le choix de 8 est en partie pédagogique: il s'agissait de pouvoir écrire nos premiers programmes assembleur avec assez de registres pour être confortable, et toutefois d'être contraint dès que les programmes deviennent un peu plus gros. 
Avec huit registres, et pas mal d'astuce (par exemple, comment échanger deux registres sans utiliser de registre intermédiaire ?), les élèves s'en sont sortis avec des statistiques de \emph{spill} mémoire raisonnables (inférieures à 1\% des instructions).
Toutefois, une vraie réponse à cette question demande de faire une étude qui couvre également (et surtout) la problématique de la compilation.

Les architectures modernes offrent typiquement entre 16 et 64 registres.
Elles offrent également des mécanismes qui exposent dans le jeu d'instruction un sous-ensemble des registres architecturaux, soit de manière explicite (les fenêtres de registres du SPARC), soit de manière implicite (le techniques de renommage qui permettent l'exécution superscalaire).

On pourrait aussi avoir un nombre de registres beaucoup plus grand avec un encodage compact des registres les plus utilisés.
\todo{relire tout cela}

\subsection{Modes d'adressage mémoire}
\subsection{Bits de compteurs}
\subsubsection{choix initiaux}
On a fait le choix de ne pas faire d'adressage par registre : en effet, cela aurait coûté 64 bits d'adresse par adressage. Les compteurs permettent de faire autant avec seulement 2 bits à chaque adresse. En contrepartie, l'arithmétique sur les pointeurs devient extrêmement coûteuse : charger une adresse dans un registre ; faire une opération arithmétique ; affecter l'adresse avec le registre. Cependant, on espère que la plupart du temps, les données sont lues de manière séquencielle, et que donc un adressage avec post-incrément suffit à limiter l'arithmétique des pointeurs.\par
Cette affirmation est à relativiser : par exemple, le pc lit les données séquentiellement la plupart du temps. De même, dans les expériences, un écran avait été mappé sur la mémoire, et on pouvait l'effacer en écrivant plusieurs fois \texttt{0x0} à son adresse. Cependant, un contre-exemple très souvent utilisé est le \texttt{push}, qui nécessite un pré-decrément (le post-incrément oblige à affecter deux fois \texttt{sp}) ou encore la multiplication de matrices, gourmande en compteurs.
\subsubsection{améliorations}
La première amélioration, proposée dès le départ est de conserver une copie de chaque compteur dans le processeur. Ainsi, les échanges de bits de compteurs ne sont nécessaires que pour synchroniser les compteurs du processeur et de la mémoire : \texttt{getctr} ne coûte plus aucun bit de compteur, on a aussi un gain sur le \texttt{push}
Ensuite, lors d'une affectation de compteurs, on n'est pas obligé d'écrire tous les bits s'ils sont envoyés poids faible d'abord. Si on envoie $n\leqslant 64$ bits à la mémoire, la mémoire peut écrire ces $n$ bits et remplire les $64-n$ autres avec des zéros. Cela diminuerait grandement le coût des affectations du pc, très proche du début de la mémoire (le code est stocké en \texttt{0x0}). Une autre idée, plus générale, serait de ne pas toucher aux $64-n$ derniers bits. On aurait un gain lors d'affectations proches en mémoire (même si bien sûr on ne peut rien garantir : \texttt{0x1000000 - 0x1 = 0xffffff})\par
Une autre amélioration, non-implémentée, serait d'ajouter des instructions d'incrémentation des compteurs par un registre ou une constante. On remplacerait les trois instructions \texttt{getctr a0 r0 ; add2 r0 r1 ; setctr a0 r0} par l'unique \texttt{incrctr a0 r0}. Si on ne gagne pas sur le nombre de bits de compteurs échangés (toujours $64$), cette instruction est assez facile à implanter en machine, on factorise un trio d'instruction assez présent dans la boucle interne de nombreux programmes (par exemple la multiplication matricielle) en une seule, et on gagne un registre.

\subsubsection{les adresses de jump}

\subsubsection{le problème de la pile}
Si avec le post-incrément, le \texttt{pull} ne coûte rien, dans la version naïve, le push est extrêmement coûteux : \texttt{push 32 r0} fait d'abord transiter $7$ bits de la mémoire au processeur pour l'opérande, $3$ pour le registre. L'instruction est lue. Il faudra ensuite faire reculer le pointeur de pile de $32$ bits : $64$ bits pour récupérer \texttt{sp}, $64$ autres pour l'affecter. Les $32$ bits de \texttt{r0} sont écrits, puis on fait de nouveau reculer le pointeur de pile : $64$ bits. Soit un total d'instructions lues de $10$, $32$ bits de lus, et $192$ bits de compteurs.\par
C'est un problème : comme on l'a vu l'efficacité du \texttt{push} détermine la quantité de registres nécessaire. La première amélioration proposée permet de faire descendre le coût du \texttt{push} à 128 bits, et plus si on décide d'un endroit adéquat pour placer le fond de la pile. Cependant, un gain énorme serait d'autoriser l'écriture avec pré-décrément : en écrivant les bits un à un à l'envers et en pré-décrément sur sp, on n'a plus besoin d'affecter sp. Le nombre de bits d'adresse dus au push retomberait à 0. Une manière assez simple de l'implémenter et de faire transiter le sens d'écriture sur le fil \texttt{Read} : 0 indiquerait post-incrément, et 1 pré-décrément. On pourrait même alors imaginer un \texttt{push} prenant en argument un compteur. Ainsi, chaque compteur pourrait devenir une pile.

\begin{table}[!h]
  \caption{Coûts des opérations}
  \label{tab:costs}
  On propose une première version naïve du coût de chaque opération, pour une architecture 64 bits. La taille de l'opcode d'une instruction étant variable, il faut à chaque fois l'ajouter dans les instructions lues.
  \begin{center}
  \begin{tabular}{|l|c|c|c|}
    \hline  
    type  & bits d'instruction & bits de données & bits de compteurs \\
    \hline  
    \hline
    \texttt{arith} \reg\ \reg\ &  $6$ & & \\
    \hline
    \texttt{arith} \reg\ \reg\ \reg\ & $9$ & & \\
    \hline
    \texttt{arith} \reg\ \const\ & $3$ + \const & & \\
    \hline
    \texttt{arith} \reg\ \reg\ \const\ & $6$ + \const & & \\
    \hline
    \texttt{r/w} \ctr\ \size\ \reg & $2$ + \size\ + $3$ & \size & \\
    \hline
    \texttt{get-,setctr} \ctr\ \reg\ & $2$ + $3$ & & $64$ \\
    \hline
    \texttt{jump} & \addr\ & & $64$ \\
    \hline
    \texttt{jumpif} \cond & $3$ + \addr\ & & $0$ ou $64$\\
    \hline
    \texttt{call} \addr & \addr\ & & $64$\\
    \hline
    \texttt{return} & & & $64$\\
    \hline
    \texttt{push} \size\ \reg & $3$ & \size & $192$\\
    \hline
  \end{tabular}
  \end{center}
Tableau d'amélioration du nombre de bits de compteurs.
  \begin{center}
    \begin{tabular}{|l|c|c|c|c|}
      \hline  
      type  & sans dédoublement & initial & pré-décrément & syncr futée  \\
      \hline  
      \hline
      \texttt{getctr} & $64$ & 0 & & \\
      \hline
      \texttt{setctr} & 64 & & & $\leqslant 64$ \\
      \hline
      \texttt{jump(if)} & 64 & & & $\leqslant 64$\\
      \hline
      \texttt{call} & 128 & 64 & & $\leqslant 64$\\
      \hline
      \texttt{return} & 64 & & & $\leqslant64$\\
      \hline
      \texttt{push} & 196 & 128 & 0 & &
      \hline
    \end{tabular}
  \end{center}
\end{table}

\section{Conclusion et perspectives}

- une étude de l'encodage d'un jeu d'instruction universel si l'on enlève la contrainte de la taille des codes

- quel réalisme et quelles applications

- un processeur dont l'encodage est reconfigurable? 
\bibliography{biblio.bib}


\appendix
\begin{table}[!h]
  \caption{Liste des instructions.}
  \label{tab:opcodes}
  Le choix des opcodes est arbitraire.
  Les opérandes d'une instruction suivent l'opcode:
  \begin{itemize}
\item \textit{reg} $\in \{\mathtt{r0}, \mathtt{r1}, ..., \mathtt{r7}\}$ et est encodé par le numéro du registre en binaire.
\item \textit{const}, \textit{shiftval} et \textit{addr} sont définis par la table \ref{tab:constantes}. La colonne \emph{ext} de la table  \ref{tab:opcodes} précise si une constante est étendue avec son signe (s) ou des zéros (z).   
\item  \textit{cond} est défini par la table~\ref{tab:conditions}.
\item \ctr\ est défini par la table~\ref{tab:counters}.
\item \textit{dir} peut être \texttt{left}, encodé par 0, ou \texttt{right}, encodé par 1.
\end{itemize}
\begin{center}
  \begin{tabular}{|l|l|l|l|l|c|}
    \hline  
    opcode  & mnemonic        & operands                      & description                                          & ext. & {MàJ flags} \\
    \hline  
    \hline  
    0000    & \texttt{add2}   & \reg\ \reg\                   & addition                                             &      & zcvn        \\
    \hline
    0001    & \texttt{add2i}  & \reg\ \const\                 & add immediate constant                               & z    & zcvn        \\
    \hline
    0010    & \texttt{sub2}   & \reg\ \reg\                   & subtraction                                          &      & zcvn        \\
    \hline
    0011    & \texttt{sub2i}  & \reg\ \const\                 & subtract immediate constant                          & z    & zcvn        \\
    \hline
    0100    & \texttt{cmp}    & \reg\ \reg\                   & comparison                                           &      & zcvn        \\
    \hline
    0101    & \texttt{cmpi}   & \reg\ \const\                 & comparison with immediate constant                   & s    & zcvn        \\
    \hline
    0110    & \texttt{let}    & \reg\ \reg\                   & register copy                                        &      &             \\
    \hline
    0111    & \texttt{leti}   & \reg\ \const\                 & fill register with constant                          & s    &             \\
    \hline
    1000    & \texttt{shift}  & \textit{dir} \reg\ \shiftval\ & logical shift                                        &      & zcn         \\
    \hline
    10010   & \texttt{readze} & \ctr\ \size\ \reg\            & read \size\ memory bits (zero-extended) to \reg\     &      &             \\
    10011   & \texttt{readse} & \ctr\ \size\ \reg\            & read \size\ memory bits (sign-extended) to \reg\     &      &             \\
    \hline
    1010    & \texttt{jump}   & \addr\                        & relative jump                                        &      &             \\
    \hline
    1011    & \texttt{jumpif} & \cond\ \addr\                 & conditional relative jump                            &      &             \\
    \hline
    110000  & \texttt{or2}    & \reg\ \reg\                   & logical bitwise or                                   &      & zcn         \\
    \hline
    110001  & \texttt{or2i}   & \reg\ \const\                 & logical bitwise or                                   & {z}  & zcn         \\
    \hline
    110010  & \texttt{and2}   & \reg\ \reg\                   & logical bitwise and                                  &      & zcn         \\
    \hline
    110011  & \texttt{and2i}  & \reg\ \const\                 & logical bitwise and                                  & {z}  & zcn         \\
    \hline
    110100  & \texttt{write}  & \ctr\ \size\ \reg\            & write the lower \size\ bits of \reg\ to mem          &      &             \\
    \hline
    110101  & \texttt{call}   & \addr\                        & sub-routine call                                     & s    &             \\
    \hline
    110110  & \texttt{setctr} & \ctr\ \reg\                   & store \reg\ to a counter                             &      &             \\
    \hline
    110111  & \texttt{getctr} & \ctr\ \reg\                   & copy the current value of a counter to \reg\         &      &             \\
    \hline
    1110000 & \texttt{push}   & \size\ \reg\                  & push value of register on stack                      &      &             \\
    \hline
    1110001 & \texttt{return} &                               & return from subroutine                               &      &             \\
    \hline
    1110010 & \texttt{add3}   & \reg\ \reg\ \reg\             &                                                      &      & zcvn        \\
    \hline
    1110011 & \texttt{add3i}  & \reg\ \reg\ \const\           &                                                      & z    & zcvn        \\
    \hline
    1110100 & \texttt{sub3}   & \reg\ \reg\ \reg\             &                                                      &      & zcvn        \\
    \hline
    1110101 & \texttt{sub3i}  & \reg\ \reg\ \const\           &                                                      & z    & zcvn        \\
    \hline
    1110110 & \texttt{and3}   & \reg\  \reg\ \reg\            &                                                      &      & zcn         \\
    \hline
    1110111 & \texttt{and3i}  & \reg\ \reg\ \const\           &                                                      & {z}  & zcn         \\
    \hline
    1111000 & \texttt{or3}    & \reg\ \reg\ \reg\             &                                                      &      & zcn         \\
    \hline
    1111001 & \texttt{or3i}   & \reg\ \reg\ \const\           &                                                      & {z}  & zcn         \\
    \hline
    1111010 & \texttt{xor3}   & \reg\ \reg\ \reg\             &                                                      &      & zcn         \\
    \hline
    1111011 & \texttt{xor3i}  & \reg\ \reg\ \const\           &                                                      & {z}  & zcn         \\
    \hline
    1111100 & \texttt{asr3}   & \reg\  \reg\ \shiftval\       &                                                      &      & zcn         \\
    \hline
    1111101 & \texttt{}       &                               & reserved                                             &      &             \\
    \hline
    1111110 & \texttt{}       &                               & reserved                                             &      &             \\
    \hline
    1111111 & \texttt{}       &                               & reserved                                             &      &             \\
    \hline
  \end{tabular}
\end{center}
\end{table}




\begin{table} 
  \caption{Les 4 compteurs. Ces deux bits sont transmis sur le signal \texttt{Select} de la figure~\ref{fig:overview}. }
  \label{tab:counters}
\begin{center}
  \begin{tabular}{|l|l|l|}
    \hline  
  encoding  & mnemonic & description \\
    \hline  
    \hline  
    00& \texttt{pc} &  program counter\\
    \hline
    01& \texttt{sp} & stack pointer\\
    \hline
    10& \texttt{a0} &  generic address counter\\
    \hline
    11& \texttt{a1} &  generic address counter\\
    \hline
  \end{tabular}
\end{center}
\end{table}





\begin{table}
  \label{tab:constantes}
  \centering
  \caption{Encodage des constantes}
  \begin{tabular}{|l|l|}
    \hline
    \multicolumn{2}{|c|}{\textit{addr} : Encodage \emph{prefix-free} des adresses et déplacements} \\
    \hline
    0 + 8 bits    & adresse ou déplacement sur 8 bits                                              \\
    \hline
    10 + 16 bits  &                                                                                \\
    \hline
    110 + 32 bits &                                                                                \\
    \hline
    111 + 64 bits &                                                                                \\
    \hline
    \hline
    \multicolumn{2}{|c|}{\textit{shiftval} : Encodage \emph{prefix-free} des constantes de shift}  \\
    \hline
    0 + 6 bits    & constante entre 0 et 63                                                        \\
    \hline
    1             & constante 1                                                                    \\
    \hline
    \hline
    \multicolumn{2}{|c|}{\textit{const} : Encodage \emph{prefix-free} des constantes ALU}          \\
    \hline
    0 + 1 bit     & constante 0 ou 1                                                               \\
    \hline
    10 + 8 bits   & octet                                                                          \\
    \hline
    110 + 32 bits &                                                                                \\
    \hline
    111 + 64 bits &                                                                                \\
    \hline
    \hline
    \multicolumn{2}{|c|}{\textit{size} : Encodage \emph{prefix-free} des tailles mémoire}          \\
    \hline
    00            & 1 bit                                                                          \\
    \hline
    01            & 4 bits                                                                         \\
    \hline
    100           & 8 bits                                                                         \\
    \hline
    101           & 16 bits                                                                        \\
    \hline
    110           & 32 bits                                                                        \\
    \hline
    111           & 64 bits                                                                        \\
    \hline
  \end{tabular}
\end{table}
\newcommand{\bool}{\mathbb{B}}
\newcommand{\booland}{\wedge}
\newcommand{\boolor}{\vee}
\newcommand{\boolnot}[1]{\overline{#1}}
\begin{table} 
  \caption{Conditions. La différence entre \texttt{sgt} et \texttt{gt} s'observe par exemple sur la comparaison entre \texttt{r0} et -1.
}
  \label{tab:conditions}
\begin{center}
  \begin{tabular}{|c|c|c||l||l|c|}
    \hline  
      &   &   & mnemonic                  & description (after \texttt{cmp} op1 op2)           & {implem.}                                                                           \\
    \hline  
    \hline  
    0 & 0 & 0 & \texttt{eq}, \texttt{z}   & equal, op1 $=$ op2                                 & $z$                                                                                 \\
    \hline
    0 & 0 & 1 & \texttt{neq}, \texttt{nz} & not equal, op1 $\neq$ op2                          & $\boolnot{z}$                                                                       \\
    \hline
    0 & 1 & 0 & \texttt{sgt}              & signed greater than, op1 $>$ op2, two's complement & $\boolnot{z} \booland (n \booland {v}) \boolor (\boolnot{n} \booland \boolnot{v}) $ \\
    \hline
    0 & 1 & 1 & \texttt{slt}              & signed smaller than, op1 $<$ op2, two's complement & $(n \booland \boolnot{v}) \boolor (\boolnot{n} \booland v) $                        \\
    \hline
    1 & 0 & 0 & \texttt{gt}               & op1 $>$ op2, unsigned                              & $\boolnot{z} \booland \boolnot{c}$                                                  \\
    \hline
    1 & 0 & 1 & \texttt{ge}, \texttt{nc}  & op1 $\ge$ op2, unsigned                            & $\boolnot{c}$                                                                       \\
    \hline
    1 & 1 & 0 & \texttt{lt}, \texttt{c}   & op1 $<$ op2, unsigned                              & $c$                                                                                 \\
    \hline
    1 & 1 & 1 & {\texttt{v}}              & {two's complement overflow}                        & {$v$}                                                                               \\
    \hline
  \end{tabular}
\end{center}
\end{table} 




\end{document}
